<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>A Novel Approach to Motor Imagery Classification via Mini-Epoch Generation | Darin Tsui </title> <meta name="author" content="Darin Tsui "> <meta name="description" content="We propose two feature selection algorithms, mini-epoch learning and mini-epoch ensemble learning, that aim to capture temporal data in EEG for motor imagery"> <meta name="keywords" content="Darin Tsui"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/icon.jpg?3f05ada74a352e791f20baa40ebf6aac"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://darintsui.github.io/projects/MotorImagery_FeatureSelection/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?3dd82e91913a2c1265c0f80e41ff39e2"></script> <script src="/assets/js/dark_mode.js?6458e63976eae16c0cbe86b97023895a"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Darin Tsui </span></a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">Home</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">A Novel Approach to Motor Imagery Classification via Mini-Epoch Generation </h1> <p class="post-description">We propose two feature selection algorithms, mini-epoch learning and mini-epoch ensemble learning, that aim to capture temporal data in EEG for motor imagery</p> </header> <article> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/featured-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/featured-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/featured-1400.webp"></source> <img src="/assets/img/featured.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Architecture" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>Classification of motor imagery tasks based on EEG signals has a wide range of applications in clinical science and Brain-Computer Interfaces (BCIs). However, most deep learning attempts at motor imagery classification fail to retain the temporal information in the EEG signals that is critical for motor imagery. Here, we propose two algorithms, mini-epoch learning and mini-epoch ensemble learning, that aim to tackle this limitation.</p> <h2 id="data-selection">Data Selection</h2> <p>Data for this project was taken from the Berlin Brain-Computer Interface (BCI) Competition IV <a href="https://www.bbci.de/competition/iv/#dataset2a" rel="external nofollow noopener" target="_blank">dataset</a> 2a. In this, we have subjects performing motor imagery tasks. Motor imagery is a cognitive process in where a subject imagines performing a movement without moving their body. In this experimental setup, subjects were asked to imagine four movements: moving the left hand, right hand, tongue, and foot.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/timing_scheme-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/timing_scheme-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/timing_scheme-1400.webp"></source> <img src="/assets/img/timing_scheme.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Timing Scheme" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="feature-selection">Feature Selection</h2> <p>We pull relevant information from the EEG signals by extracting the data 1 second to 4 seconds after the stimulus was cued. From here, we divide the input signals in the time domain into small sub-intervals, which we will refer to as “mini-epochs”. We experimented with two mini-epoch generation strategies: fixed and sliding.</p> <ol> <li>Fixed mini-epoch window: The time signal is divided into N non-overlapping intervals with equal length. In this approach, the next interval starts from the point where the first interval ends as shown below. Each mini-epoch spans T = 3 N seconds</li> </ol> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/interval-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/interval-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/interval-1400.webp"></source> <img src="/assets/img/interval.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Fixed window" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ol> <li>Sliding mini-epoch window: With fixed window length T second of each epoch and the number of mini- epochs N determined, the mini-epoch can be gener- ated by sliding the window by increment of ∆t = (3−T)/(N−1) seconds. Using this approach, we can more flexibly determine the mini-epoch duration and the number of mini-epochs while spanning the full time sequence via varying the parameters T and N . These mini-epochs can be overlapping as shown in Figure 3. Using this approach, we can more clearly observe the effect of trimming the EEG signal into sub-intervals and look for an optimal mini-epoch length that extracts the significance of different time steps for the EEG signal.</li> </ol> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/sliding-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/sliding-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/sliding-1400.webp"></source> <img src="/assets/img/sliding.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Sliding window" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="preprocessing">Preprocessing</h2> <p>In our approach, after adding our mini-epoch window implementation, we follow the below pipeline.</p> <ol> <li> <p>Filter the signal through a bandpass filter from 7Hz to 30Hz, which is the only frequency range containing relevant information about the motor imagery tasks.</p> </li> <li> <p>Remove signals from EOG channels and consider only the 22 EEG channels for motor imagery tasks.</p> </li> <li> <p>Apply wavelet packet decomposition (WPD) tech- nique to the resulting signal to extract features in the frequency domain. WPD is an extension of Wavelet Decomposition that comprises several bases with more filtering operations applied to the wavelets.</p> </li> <li> <p>Apply Common Spatial Pattern (CSP) technique for extracting spatial features from the signal. It has been widely used for feature extraction in EEG-based BCI systems for motor imagery.</p> </li> </ol> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/preproc-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/preproc-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/preproc-1400.webp"></source> <img src="/assets/img/preproc.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Signal processing pipeline" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="learning-architectures">Learning Architectures</h2> <p>We explore two learning architectures: mini-epoch learning and mini-epoch ensemble learning.</p> <ol> <li> <strong>Mini-epoch learning</strong>: After signal processing is applied to our data, we create a feature set out of the resulting signals. From here, this feature set is fed into a classifier to output the most probable class out of the entire time series. This classifier can be any classification algorithm, such as multi-layer perception (MLP), XGBoost, and support vector machine (SVM).</li> </ol> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/featured-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/featured-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/featured-1400.webp"></source> <img src="/assets/img/featured.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Mini-epoch learning" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ol> <li> <strong>Mini-epoch ensemble learning</strong>: In this implementation, after signal processing is applied to our data, we feed the resulting signals to a selected base multi-class classifier. However, instead of directly yielding the predicted label, these base classifiers are employed to generate the normalized scores for each label. These nor- malized scores indicate the probability distribution of each label predicted within each mini-epoch. Like the classifier in the mini-epoch learning algorithm, the base classifiers can be implemented with any classification algorithm. These N base classifiers form the ensemble to make the final prediction for the last step.</li> </ol> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/mini_epoch_architecture-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/mini_epoch_architecture-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/mini_epoch_architecture-1400.webp"></source> <img src="/assets/img/mini_epoch_architecture.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Mini-epoch ensemble learning" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="training-and-testing">Training and Testing</h2> <p>We look to test our feature selection technique using three classifiers: multi-layer perceptron (MLP), XGBoost, and SVM. We find that implementing our mini-epoch learning algorithm with SVM proved to be the most accurate in identifying different motor imagery tasks, with an accuracy of 63.16%.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/mini_epoch_table-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/mini_epoch_table-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/mini_epoch_table-1400.webp"></source> <img src="/assets/img/mini_epoch_table.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Table 1" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>Implementing mini-epoch ensemble learning with XGB recorded the highest accuracy of 61.04%.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/ensemble_table-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/ensemble_table-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/ensemble_table-1400.webp"></source> <img src="/assets/img/ensemble_table.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Table 2" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="acknowledgements">Acknowledgements</h2> <p>This group project was inspired by ECE 271B: Statistical Learning II, taught at UC San Diego under Dr. Manuela Vasconcelos.</p> <p>You can find the link to the repository <a href="https://github.com/darintsui/MotorImageryEpoching" rel="external nofollow noopener" target="_blank">here</a> as well as the report <a href="..\..\assets\pdf\EpochGeneration.pdf">here</a>. You can also find the presentation <a href="..\..\assets\pdf\Presentation.pdf">here</a>.</p> </article> </div> </div> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>